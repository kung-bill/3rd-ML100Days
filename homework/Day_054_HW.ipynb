{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "* 試著想想看, 非監督學習是否有可能使用評價函數 (Metric) 來鑑別好壞呢?  \n",
    "(Hint : 可以分為 \"有目標值\" 與 \"無目標值\" 兩個方向思考)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> 1. 無目標值的非監督式學習，也就是 Clustering 。 <br>\n",
    "> Clustering 試圖將 Dataset 中的樣本分成幾個不同的類別。目的是研究對這些沒有Label 的 樣本點來學習，試圖了解這些樣本的內在性質與規律。\n",
    "> Clustering 問題的 Metric 函數，直觀來看我們希望\"物以類聚\"，也就是同一個類別的樣本，彼此要盡可能的相似；不同類別的樣本，要盡可能有顯著差異。\n",
    "> 對於一組 Clustering  $\\mathcal C = \\{C_1, C_2, \\cdots, C_k\\}$，我們定義： <br>\n",
    ">> 1. $\\text{avg}(\\mathcal C)  = \\frac{2}{|\\mathcal C| (|\\mathcal C| - 1)}\\sum_{1 \\leq i < j \\leq |\\mathcal C|} d(x_i, x_j)$ <br>\n",
    ">> 2. $\\text{diam}(\\mathcal C) = \\max_{1 \\leq i < j \\leq |\\mathcal C|} d(x_i, x_j)$\n",
    ">> 3. $d_\\min(C_i, C_j) = \\min_{x_i \\in C_i, x_j \\in C_j} d(x_i, x_j)$\n",
    ">> 4. $d_{\\text{cen}}(C_i, C_j) = d(\\mu_i, \\mu_j)$ 其中 $\\mu_i = \\frac{1}{|C_i|}\\sum_{1\\leq i \\leq |C_i|}  x_i$ <br> <br>\n",
    "> 基於以上我們可以定義 DBI (Davies-Bouldin Index)：\n",
    ">>  $$\\text{DBI} = \\frac{1}{k}\\sum_{i=1}^k \\max_{j\\neq i} \\left(\\frac{ \\text{avg}(C_i) + \\text{avg}(C_j)}{d_{\\text{cen}}(C_i, C_j)}\\right)$$ <br>\n",
    "> 組內 square error 的和：\n",
    ">> $$ E = \\sum_{i=1}^k\\sum_{x \\in C_i} \\| x - \\mu_i \\|_2^2$$\n",
    "> 2. 有目標值得非監督學習，"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
